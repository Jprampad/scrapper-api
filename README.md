# ğŸ•·ï¸ Blog Scraper API

API REST para extraer artÃ­culos del blog de forma asÃ­ncrona y escalable.

## ğŸš€ CaracterÃ­sticas

- âœ¨ Scraping asÃ­ncrono de artÃ­culos
- ğŸ“Š Cola de trabajos con estado
- ğŸ“ ExportaciÃ³n a Google Sheets
- ğŸ”” Notificaciones vÃ­a webhook
- ğŸ“± DocumentaciÃ³n interactiva con Swagger

## ğŸ¤– Modelos de Scraping

### 1. Base Scraper (Secuencial)

- ğŸ”„ Procesamiento secuencial de artÃ­culos uno por uno
- ğŸ¯ Usa Selenium para cargar pÃ¡ginas dinÃ¡micamente
- âš¡ Menor consumo de recursos y memoria
- ğŸ“ CaracterÃ­sticas:
  - Procesamiento lineal
  - Sin concurrencia
  - Ideal para pocas pÃ¡ginas (<15 artÃ­culos)
- ğŸ“ Archivo: `scrapper.py`

### 2. Optimized Scraper (Concurrente)

- ğŸ”„ Procesamiento concurrente con ThreadPoolExecutor
- ğŸš€ 2.4x mÃ¡s rÃ¡pido que el base
- ğŸ’ª Mejor manejo de mÃºltiples artÃ­culos
- ğŸ“ CaracterÃ­sticas:
  - MÃºltiples threads simultÃ¡neos
  - Pool de 5 workers
  - Ideal para volumen medio (15-100 artÃ­culos)
- ğŸ“ Archivo: `scrapper_optimized.py`

### 3. Ultra Scraper (AsÃ­ncrono)

- âš¡ Procesamiento asÃ­ncrono con asyncio y aiohttp
- ğŸƒ 15.7x mÃ¡s rÃ¡pido que el base
- ğŸ”¥ Ideal para grandes volÃºmenes
- ğŸ“ CaracterÃ­sticas avanzadas:
  - Cache de URLs y resultados
  - SemÃ¡foros para control de concurrencia
  - Timeouts configurables
  - uvloop para mejor rendimiento
  - Ideal para grandes volÃºmenes (>100 artÃ­culos)
- ğŸ“ Archivo: `scrapper_ultra_optimized.py`

## ğŸ“Š Comparativa de Rendimiento

| CaracterÃ­stica          | Base     | Optimized | Ultra    |
|------------------------|----------|-----------|----------|
| Tipo de procesamiento  | Secuencial| Concurrente| AsÃ­ncrono|
| Velocidad relativa     | 1x       | 2.4x      | 15.7x    |
| Uso de memoria        | Bajo     | Medio     | Alto     |
| Complejidad           | Simple   | Media     | Alta     |
| ArtÃ­culos recomendados| <15      | 15-100    | >100     |
| Cache                 | No       | No        | SÃ­       |

## ğŸ“Š Rendimiento por Modelo

La siguiente tabla muestra el tiempo de ejecuciÃ³n (en segundos) para cada modelo de scraping segÃºn la categorÃ­a:

| CategorÃ­a             | ArtÃ­culos | Base   | Optimized | Ultra  | Mejora |
|----------------------|-----------|--------|-----------|--------|--------|
| Todas las categorÃ­as | 406       | 400.50 | 164.25    | 25.39  | 93.66% |
| Pymes                | 139       | 134.15 | 51.33     | 24.37  | 81.83% |
| Corporativos         | 114       | 110.49 | 43.93     | 20.50  | 81.45% |
| EducaciÃ³n Financiera | 80        | 83.18  | 30.88     | 16.16  | 80.57% |
| Emprendedores        | 32        | 42.45  | 17.69     | 10.05  | 76.33% |
| Xepelin              | 27        | 31.33  | 17.64     | 9.62   | 69.29% |
| Casos de Ã‰xito       | 14        | 21.67  | 12.69     | 8.29   | 61.74% |

## ğŸ› ï¸ Requisitos

- Python 3.9+
- pip
- virtualenv (opcional pero recomendado)

### ğŸš€ Request bÃ¡sica (solo parÃ¡metros requeridos)

curl -X POST http://127.0.0.1:8000/scraping
    -H "Content-Type: application/json"
    -d '{
          "category": "xepelin",
          "webhook": "https://hooks.zapier.com/hooks/catch/11217441/bfemddr"
        }'

### âœ¨ Request completa (con parÃ¡metros opcionales)

curl -X POST http://127.0.0.1:8000/scraping
    -H "Content-Type: application/json"
    -d '{
          "category": "xepelin",
          "webhook": "https://hooks.zapier.com/hooks/catch/11217441/bfemddr",
          "email": "jpramirez5@uc.cl",
          "model": "base"
        }'

## ğŸš€ InstalaciÃ³n y EjecuciÃ³n

### Paso 1: Clonar el repositorio
``` bash
git clone https://github.com/usuario/scraper-api.git
cd scraper-api
```

### Paso 2: Crear y activar entorno virtual

En Windows:
``` bash
python -m venv venv
.\venv\Scripts\activate
```

En macOS/Linux:
``` bash
python3 -m venv venv
source venv/bin/activate
```

### Paso 3: Instalar dependencias
``` bash
bash
pip install -r requirements.txt
```

### Paso 4: Configurar variables de entorno
1. Crea un archivo `.env` en la raÃ­z del proyecto
2. AÃ±ade las siguientes variables:

``` env
Solicitar variables
DEBUG=true
```

### Paso 5: ğŸƒâ€â™‚ï¸ Ejecutar la API


Iniciar servidor de desarrollo
``` bash
uvicorn main:app --reload
```
```
La API estarÃ¡ disponible en:
http://localhost:8000
DocumentaciÃ³n: http://localhost:8000/docs
```